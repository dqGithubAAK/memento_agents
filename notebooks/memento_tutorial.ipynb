{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca54d05c",
   "metadata": {},
   "source": [
    "# Memento Framework Tutorial\n",
    "\n",
    "Learn how to build agents that learn from experience using case-based reasoning.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers:\n",
    "1. **Basic Memento Setup**: Initialize agents with memory\n",
    "2. **Case-Based Reasoning**: Store and retrieve past experiences\n",
    "3. **Parametric Memory**: Train neural retrievers\n",
    "4. **Integration Patterns**: Combine with other frameworks\n",
    "5. **Production Deployment**: Best practices\n",
    "\n",
    "**Prerequisites**: Understanding of LLM agents and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a643e",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Case-Based Reasoning\n",
    "\n",
    "### What is CBR?\n",
    "\n",
    "Case-Based Reasoning solves new problems by:\n",
    "1. **Retrieve**: Find similar past cases\n",
    "2. **Reuse**: Adapt solutions from those cases\n",
    "3. **Revise**: Test and refine the solution\n",
    "4. **Retain**: Store the new experience\n",
    "\n",
    "### Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple in-memory case store\n",
    "\n",
    "class SimpleCase:\n",
    "    def __init__(self, problem, solution, success):\n",
    "        self.problem = problem\n",
    "        self.solution = solution\n",
    "        self.success = success\n",
    "\n",
    "class SimpleCBR:\n",
    "    def __init__(self):\n",
    "        self.cases = []\n",
    "    \n",
    "    def retrieve(self, problem, k=3):\n",
    "        \"\"\"Retrieve most similar cases (simple keyword matching).\"\"\"\n",
    "        scored = []\n",
    "        for case in self.cases:\n",
    "            # Simple similarity: count common words\n",
    "            problem_words = set(problem.lower().split())\n",
    "            case_words = set(case.problem.lower().split())\n",
    "            similarity = len(problem_words & case_words)\n",
    "            scored.append((similarity, case))\n",
    "        \n",
    "        # Return top-k\n",
    "        scored.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [case for _, case in scored[:k]]\n",
    "    \n",
    "    def store(self, problem, solution, success):\n",
    "        \"\"\"Store a new case.\"\"\"\n",
    "        case = SimpleCase(problem, solution, success)\n",
    "        self.cases.append(case)\n",
    "\n",
    "# Example usage\n",
    "cbr = SimpleCBR()\n",
    "\n",
    "# Store some experiences\n",
    "cbr.store(\n",
    "    problem=\"Find all PDF files in Documents\",\n",
    "    solution=\"find ~/Documents -name '*.pdf'\",\n",
    "    success=True\n",
    ")\n",
    "\n",
    "cbr.store(\n",
    "    problem=\"Find all image files modified yesterday\",\n",
    "    solution=\"find . -name '*.jpg' -mtime -1\",\n",
    "    success=True\n",
    ")\n",
    "\n",
    "cbr.store(\n",
    "    problem=\"Count lines in all Python files\",\n",
    "    solution=\"find . -name '*.py' | xargs wc -l\",\n",
    "    success=True\n",
    ")\n",
    "\n",
    "# Retrieve similar cases for a new problem\n",
    "new_problem = \"Find all text files in Downloads\"\n",
    "similar_cases = cbr.retrieve(new_problem, k=2)\n",
    "\n",
    "print(f\"New Problem: {new_problem}\\n\")\n",
    "print(\"Similar Past Cases:\")\n",
    "for i, case in enumerate(similar_cases, 1):\n",
    "    print(f\"\\n{i}. {case.problem}\")\n",
    "    print(f\"   Solution: {case.solution}\")\n",
    "    print(f\"   Success: {case.success}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db34d6",
   "metadata": {},
   "source": [
    "### Key Insight\n",
    "\n",
    "The agent can now learn from experience:\n",
    "- Sees that similar file-finding problems use `find` command\n",
    "- Adapts the pattern for the new file type (txt vs pdf)\n",
    "- No model fine-tuning needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4267d8",
   "metadata": {},
   "source": [
    "## Part 2: Semantic Retrieval with Embeddings\n",
    "\n",
    "Simple keyword matching is limited. Let's use embeddings for semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ceb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install sentence-transformers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "class SemanticCase:\n",
    "    def __init__(self, problem, solution, success, embedding=None):\n",
    "        self.problem = problem\n",
    "        self.solution = solution\n",
    "        self.success = success\n",
    "        self.embedding = embedding\n",
    "\n",
    "class SemanticCBR:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.encoder = SentenceTransformer(model_name)\n",
    "        self.cases = []\n",
    "    \n",
    "    def store(self, problem, solution, success):\n",
    "        \"\"\"Store case with embedding.\"\"\"\n",
    "        embedding = self.encoder.encode(problem)\n",
    "        case = SemanticCase(problem, solution, success, embedding)\n",
    "        self.cases.append(case)\n",
    "    \n",
    "    def retrieve(self, problem: str, k: int = 3, \n",
    "                 success_only: bool = False) -> List[Tuple[float, SemanticCase]]:\n",
    "        \"\"\"Retrieve most semantically similar cases.\"\"\"\n",
    "        # Encode query\n",
    "        query_embedding = self.encoder.encode(problem)\n",
    "        \n",
    "        # Compute cosine similarity with all cases\n",
    "        scored = []\n",
    "        for case in self.cases:\n",
    "            if success_only and not case.success:\n",
    "                continue\n",
    "            \n",
    "            # Cosine similarity\n",
    "            similarity = np.dot(query_embedding, case.embedding) / (\n",
    "                np.linalg.norm(query_embedding) * np.linalg.norm(case.embedding)\n",
    "            )\n",
    "            scored.append((similarity, case))\n",
    "        \n",
    "        # Sort by similarity\n",
    "        scored.sort(reverse=True, key=lambda x: x[0])\n",
    "        return scored[:k]\n",
    "\n",
    "print(\"Semantic CBR system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create semantic CBR system\n",
    "semantic_cbr = SemanticCBR()\n",
    "\n",
    "# Store diverse experiences\n",
    "experiences = [\n",
    "    (\"Search for emails from john@company.com\", \"email_search sender:john@company.com\", True),\n",
    "    (\"Find messages sent yesterday\", \"email_search date:yesterday\", True),\n",
    "    (\"Calculate average of numbers in file\", \"awk '{sum+=$1} END {print sum/NR}' data.txt\", True),\n",
    "    (\"Get weather forecast for Tokyo\", \"curl 'wttr.in/Tokyo'\", True),\n",
    "    (\"Download file from URL\", \"wget https://example.com/file.pdf\", False),  # Failed\n",
    "    (\"Extract URLs from HTML\", \"grep -oP 'href=\\\"\\K[^\\\"]+' page.html\", True),\n",
    "    (\"Convert image format\", \"convert input.png output.jpg\", True),\n",
    "]\n",
    "\n",
    "for problem, solution, success in experiences:\n",
    "    semantic_cbr.store(problem, solution, success)\n",
    "\n",
    "print(f\"Stored {len(semantic_cbr.cases)} cases in memory\\n\")\n",
    "\n",
    "# Test semantic retrieval\n",
    "test_queries = [\n",
    "    \"Find emails from alice@example.com\",\n",
    "    \"Compute mean of values in dataset\",\n",
    "    \"Check weather in London\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    similar = semantic_cbr.retrieve(query, k=2, success_only=True)\n",
    "    \n",
    "    for i, (score, case) in enumerate(similar, 1):\n",
    "        print(f\"\\n{i}. Similarity: {score:.3f}\")\n",
    "        print(f\"   Problem: {case.problem}\")\n",
    "        print(f\"   Solution: {case.solution}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f3ec5",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "Semantic retrieval finds **conceptually similar** cases, not just keyword matches:\n",
    "- \"Find emails from alice\" → \"Search for emails from john\"\n",
    "- \"Compute mean\" → \"Calculate average\"\n",
    "- \"Check weather in London\" → \"Get weather forecast for Tokyo\"\n",
    "\n",
    "This is the foundation of Memento's memory system!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b099586",
   "metadata": {},
   "source": [
    "## Part 3: Building a Simple Memory-Augmented Agent\n",
    "\n",
    "Let's create an agent that uses CBR to solve tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ae83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryAugmentedAgent:\n",
    "    \"\"\"Agent that learns from experience.\"\"\"\n",
    "    \n",
    "    def __init__(self, cbr_system: SemanticCBR):\n",
    "        self.cbr = cbr_system\n",
    "    \n",
    "    def solve(self, task: str) -> str:\n",
    "        \"\"\"Solve a task using memory.\"\"\"\n",
    "        print(f\"\\nTask: {task}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # 1. Retrieve relevant memories\n",
    "        similar_cases = self.cbr.retrieve(task, k=3, success_only=True)\n",
    "        \n",
    "        if not similar_cases:\n",
    "            print(\"No relevant memories found. Solving from scratch...\")\n",
    "            return self._solve_from_scratch(task)\n",
    "        \n",
    "        print(f\"\\nRetrieved {len(similar_cases)} relevant memories:\\n\")\n",
    "        \n",
    "        # 2. Show retrieved cases\n",
    "        for i, (score, case) in enumerate(similar_cases, 1):\n",
    "            print(f\"{i}. [{score:.3f}] {case.problem}\")\n",
    "            print(f\"   → {case.solution}\\n\")\n",
    "        \n",
    "        # 3. Adapt solution from most similar case\n",
    "        best_score, best_case = similar_cases[0]\n",
    "        \n",
    "        print(f\"Adapting solution from most similar case (score={best_score:.3f})...\")\n",
    "        \n",
    "        # Simple adaptation (in practice, use LLM)\n",
    "        adapted_solution = self._adapt_solution(task, best_case)\n",
    "        \n",
    "        print(f\"\\nProposed Solution: {adapted_solution}\\n\")\n",
    "        \n",
    "        return adapted_solution\n",
    "    \n",
    "    def learn(self, task: str, solution: str, success: bool):\n",
    "        \"\"\"Store experience in memory.\"\"\"\n",
    "        self.cbr.store(task, solution, success)\n",
    "        print(f\"✓ Stored experience: {task} [{('Success' if success else 'Failure')}]\")\n",
    "    \n",
    "    def _solve_from_scratch(self, task: str) -> str:\n",
    "        \"\"\"Fallback when no memories available.\"\"\"\n",
    "        # In practice, use LLM without memory context\n",
    "        return \"[No memory guidance - would use base LLM]\"\n",
    "    \n",
    "    def _adapt_solution(self, task: str, case: SemanticCase) -> str:\n",
    "        \"\"\"Adapt solution from similar case.\"\"\"\n",
    "        # In practice, prompt LLM to adapt\n",
    "        # For demo, just show the retrieved solution\n",
    "        return f\"[Adapted from: {case.solution}]\"\n",
    "\n",
    "print(\"Memory-augmented agent created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e668c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with the CBR system we built earlier\n",
    "agent = MemoryAugmentedAgent(semantic_cbr)\n",
    "\n",
    "# Test on new tasks\n",
    "new_tasks = [\n",
    "    \"Find all emails from support@company.com in the last week\",\n",
    "    \"What's the weather in Paris?\",\n",
    "    \"Calculate sum of numbers in data.csv\"\n",
    "]\n",
    "\n",
    "for task in new_tasks:\n",
    "    solution = agent.solve(task)\n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a3039",
   "metadata": {},
   "source": [
    "### Key Benefits\n",
    "\n",
    "1. **Faster**: Reuse known solutions instead of reasoning from scratch\n",
    "2. **More Accurate**: Learn from successful strategies\n",
    "3. **Continual**: Improves over time as more experiences accumulate\n",
    "4. **Efficient**: No model fine-tuning required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd70d5",
   "metadata": {},
   "source": [
    "## Part 4: Parametric Memory (Neural Retriever)\n",
    "\n",
    "So far we used fixed embeddings. Memento trains a neural network to **learn** which cases are most relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b56d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch if needed\n",
    "# !pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class MemoryRetrieverClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network that learns to score query-case relevance.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Encode [QUERY] query [CASE] case [PLAN] plan\n",
    "    2. Extract [CLS] embedding\n",
    "    3. Binary classifier: relevant or not\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Pre-trained encoder\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # Classification head\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 2)  # [irrelevant, relevant]\n",
    "        )\n",
    "    \n",
    "    def forward(self, query: str, case: str):\n",
    "        \"\"\"Score query-case pair.\"\"\"\n",
    "        # Format input\n",
    "        text = f\"[QUERY] {query} [CASE] {case}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        # Encode\n",
    "        outputs = self.encoder(**inputs)\n",
    "        \n",
    "        # [CLS] embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(cls_embedding)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def predict_relevance(self, query: str, case: str) -> float:\n",
    "        \"\"\"Predict relevance score (0-1).\"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(query, case)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            relevance_score = probs[0, 1].item()  # P(relevant)\n",
    "        return relevance_score\n",
    "\n",
    "print(\"Neural retriever model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd675b",
   "metadata": {},
   "source": [
    "### Training the Retriever\n",
    "\n",
    "The key insight: **Learn from task outcomes**\n",
    "\n",
    "- If a retrieved case led to success → Positive training example\n",
    "- If a retrieved case led to failure → Negative training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate training data\n",
    "\n",
    "training_examples = [\n",
    "    # (query, case, label)\n",
    "    # Label: 1 = relevant (led to success), 0 = irrelevant (led to failure)\n",
    "    \n",
    "    # Positive examples (relevant retrievals)\n",
    "    (\"Find emails from bob@company.com\", \"Search for emails from john@company.com\", 1),\n",
    "    (\"Calculate mean of values\", \"Calculate average of numbers in file\", 1),\n",
    "    (\"Weather in London\", \"Get weather forecast for Tokyo\", 1),\n",
    "    \n",
    "    # Negative examples (irrelevant retrievals)\n",
    "    (\"Find emails from bob@company.com\", \"Convert image format\", 0),\n",
    "    (\"Calculate mean of values\", \"Download file from URL\", 0),\n",
    "    (\"Weather in London\", \"Extract URLs from HTML\", 0),\n",
    "]\n",
    "\n",
    "print(f\"Training dataset: {len(training_examples)} examples\")\n",
    "print(f\"  Positive: {sum(1 for _, _, label in training_examples if label == 1)}\")\n",
    "print(f\"  Negative: {sum(1 for _, _, label in training_examples if label == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df943493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (simplified)\n",
    "\n",
    "def train_retriever(model, training_data, epochs=3, lr=2e-5):\n",
    "    \"\"\"Train the retriever model.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for query, case, label in training_data:\n",
    "            # Forward pass\n",
    "            logits = model(query, case)\n",
    "            \n",
    "            # Compute loss\n",
    "            labels = torch.tensor([label])\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            if pred == label:\n",
    "                correct += 1\n",
    "        \n",
    "        # Print epoch stats\n",
    "        avg_loss = total_loss / len(training_data)\n",
    "        accuracy = correct / len(training_data)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Loss={avg_loss:.4f}, Accuracy={accuracy:.2%}\")\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Initialize and train (commented out to avoid long execution)\n",
    "# retriever = MemoryRetrieverClassifier()\n",
    "# retriever = train_retriever(retriever, training_examples)\n",
    "\n",
    "print(\"\\nTraining procedure defined!\")\n",
    "print(\"In practice, this runs on 1000s of examples to learn optimal retrieval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6a4b0",
   "metadata": {},
   "source": [
    "### Why Train a Retriever?\n",
    "\n",
    "**Fixed Embeddings** (Part 2):\n",
    "- Use off-the-shelf sentence encoders\n",
    "- No task-specific tuning\n",
    "- May retrieve irrelevant cases\n",
    "\n",
    "**Learned Retriever** (Part 4):\n",
    "- ✅ Learns task-specific relevance\n",
    "- ✅ Improves from experience\n",
    "- ✅ Adapts to user's domain\n",
    "- ✅ Higher quality retrievals → better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc66f8",
   "metadata": {},
   "source": [
    "## Part 5: Framework Comparison\n",
    "\n",
    "### Option 1: Pure Memento\n",
    "\n",
    "Use Memento's hierarchical agent out-of-the-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for pure Memento approach\n",
    "\n",
    "\"\"\"\n",
    "from Memento.client.parametric_memory_cbr import HierarchicalClientWithMemory\n",
    "from Memento.memory.parametric_memory import CaseRetriever\n",
    "\n",
    "# 1. Load trained retriever\n",
    "retriever = CaseRetriever.load('models/retriever.pt')\n",
    "\n",
    "# 2. Initialize agent\n",
    "agent = HierarchicalClientWithMemory(\n",
    "    planner_model='gpt-4-turbo',\n",
    "    executor_model='o3-mini',\n",
    "    memory_retriever=retriever,\n",
    "    memory_top_k=8\n",
    ")\n",
    "\n",
    "# 3. Run task\n",
    "result = agent.run('Find the population of Tokyo')\n",
    "print(result.answer)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Pure Memento Approach:\")\n",
    "print(\"+  Fixed architecture (planner + executor)\")\n",
    "print(\"+  Built-in memory system\")\n",
    "print(\"+  Automatic training pipeline\")\n",
    "print(\"-  Less flexibility in agent design\")\n",
    "print(\"-  Research codebase (not production-hardened)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b94aa",
   "metadata": {},
   "source": [
    "### Option 2: LangGraph + Memory Concepts\n",
    "\n",
    "Use LangGraph for agent framework, add Memento-style memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for LangGraph + Memory\n",
    "\n",
    "\"\"\"\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "class MemoryAugmentedLangGraphAgent:\n",
    "    def __init__(self, llm, tools, memory_retriever):\n",
    "        self.memory = memory_retriever\n",
    "        self.agent = create_react_agent(llm, tools)\n",
    "    \n",
    "    def run(self, query):\n",
    "        # 1. Retrieve relevant cases\n",
    "        cases = self.memory.retrieve(query, k=5)\n",
    "        \n",
    "        # 2. Augment query with memory\n",
    "        memory_context = format_cases(cases)\n",
    "        augmented_query = f\"{memory_context}\\n\\nTask: {query}\"\n",
    "        \n",
    "        # 3. Run LangGraph agent\n",
    "        result = self.agent.invoke({'messages': [('user', augmented_query)]})\n",
    "        \n",
    "        # 4. Store experience\n",
    "        self.memory.store(query, result, success=True)\n",
    "        \n",
    "        return result\n",
    "\"\"\"\n",
    "\n",
    "print(\"LangGraph + Memory Approach:\")\n",
    "print(\"+  Production-ready framework (LangGraph)\")\n",
    "print(\"+  Flexible agent architecture\")\n",
    "print(\"+  Native tool integration\")\n",
    "print(\"+  Human-in-the-loop support\")\n",
    "print(\"-  Need to implement training pipeline\")\n",
    "print(\"-  More setup required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ee3b5",
   "metadata": {},
   "source": [
    "### Option 3: Custom from Scratch\n",
    "\n",
    "Build everything yourself for maximum control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ae8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom approach (what we built in Parts 1-4!)\n",
    "\n",
    "print(\"Custom Approach:\")\n",
    "print(\"+  Complete control over architecture\")\n",
    "print(\"+  Can implement novel algorithms\")\n",
    "print(\"+  No framework constraints\")\n",
    "print(\"-  Most implementation work\")\n",
    "print(\"-  Need to handle edge cases\")\n",
    "print(\"-  Slower development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b9f72",
   "metadata": {},
   "source": [
    "### Recommendation\n",
    "\n",
    "**For Production Systems**: LangGraph + Memory\n",
    "- Use battle-tested framework\n",
    "- Add memory components from Memento\n",
    "- Best of both worlds\n",
    "\n",
    "**For Research**: Pure Memento or Custom\n",
    "- Memento: Fast prototyping with memory\n",
    "- Custom: Maximum flexibility for novel ideas\n",
    "\n",
    "**For Learning**: Start with custom (Parts 1-4)\n",
    "- Understand core concepts\n",
    "- Then use frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ec70e",
   "metadata": {},
   "source": [
    "## Part 6: Integration with ARE\n",
    "\n",
    "Combining Memento's learning with ARE's evaluation environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95745b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-level integration architecture\n",
    "\n",
    "print(\"\"\"\n",
    "ARE + Memento Integration:\n",
    "\n",
    "1. ARE provides dynamic evaluation environment\n",
    "   - Complex scenarios\n",
    "   - Rich tool ecosystem\n",
    "   - Success/failure validation\n",
    "\n",
    "2. Agent executes tasks\n",
    "   - Retrieves relevant memories\n",
    "   - Plans and executes\n",
    "   - Uses ARE tools\n",
    "\n",
    "3. Derive rewards from outcomes\n",
    "   - Binary: Success = 1, Failure = 0\n",
    "   - Shaped: Include efficiency, speed\n",
    "\n",
    "4. Store experiences in Memento\n",
    "   - Full execution trace\n",
    "   - Tools used\n",
    "   - Reward signal\n",
    "\n",
    "5. Train retriever periodically\n",
    "   - Batch training every N scenarios\n",
    "   - Improve retrieval policy\n",
    "   - Deploy updated model\n",
    "\n",
    "Result: Agent improves over time!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6a15d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Case-Based Reasoning**: Solve problems using past experiences\n",
    "2. **Semantic Retrieval**: Find relevant cases using embeddings\n",
    "3. **Memory-Augmented Agents**: Agents that learn from experience\n",
    "4. **Parametric Memory**: Train neural networks for better retrieval\n",
    "5. **Framework Options**: LangGraph, Memento, or custom\n",
    "6. **ARE Integration**: Continual learning in evaluation environments\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- ✅ **No Fine-Tuning**: Learn without updating LLM weights\n",
    "- ✅ **Continual Learning**: Improve automatically from experience\n",
    "- ✅ **Task-Agnostic**: Works across diverse problem types\n",
    "- ✅ **Scalable**: Add more memories without retraining base model\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Read [MEMENTO_GUIDE.md](../MEMENTO_GUIDE.md) for deeper dive\n",
    "2. Read [INTEGRATION_ARE_MEMENTO.md](../INTEGRATION_ARE_MEMENTO.md) for full architecture\n",
    "3. Try ARE tutorials: [01_understanding_are_framework.ipynb](01_understanding_are_framework.ipynb)\n",
    "4. Explore [03_agent_with_memory.ipynb](03_agent_with_memory.ipynb) for advanced memory patterns\n",
    "5. Implement your own memory-augmented agent!\n",
    "\n",
    "### References\n",
    "\n",
    "- **Memento Repository**: https://github.com/Agent-on-the-Fly/Memento\n",
    "- **ARE Repository**: https://github.com/facebookresearch/meta-agents-research-environments\n",
    "- **GAIA Benchmark**: https://huggingface.co/gaia-benchmark\n",
    "- **LangGraph**: https://langchain-ai.github.io/langgraph/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
